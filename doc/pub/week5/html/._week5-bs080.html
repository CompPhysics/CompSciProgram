<!--
HTML file automatically generated from DocOnce source
(https://github.com/doconce/doconce/)
doconce format html week5.do.txt --html_style=bootstrap --pygments_html_style=default --html_admon=bootstrap_panel --html_output=week5-bs --no_mako
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/doconce/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Solving differential equations and start CNNs">
<title>Solving differential equations and start CNNs</title>
<!-- Bootstrap style: bootstrap -->
<!-- doconce format html week5.do.txt --html_style=bootstrap --pygments_html_style=default --html_admon=bootstrap_panel --html_output=week5-bs --no_mako -->
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css" rel="stylesheet">
<!-- not necessary
<link href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
-->
<style type="text/css">
/* Add scrollbar to dropdown menus in bootstrap navigation bar */
.dropdown-menu {
   height: auto;
   max-height: 400px;
   overflow-x: hidden;
}
/* Adds an invisible element before each target to offset for the navigation
   bar */
.anchor::before {
  content:"";
  display:block;
  height:50px;      /* fixed header height for style bootstrap */
  margin:-50px 0 0; /* negative fixed header height */
}
</style>
</head>

<!-- tocinfo
{'highest level': 2,
 'sections': [('Plan for week 5', 2, None, 'plan-for-week-5'),
              ('Using Automatic differentiation',
               2,
               None,
               'using-automatic-differentiation'),
              ('Solving ODEs with Deep Learning',
               2,
               None,
               'solving-odes-with-deep-learning'),
              ('Ordinary Differential Equations',
               2,
               None,
               'ordinary-differential-equations'),
              ('The trial solution', 2, None, 'the-trial-solution'),
              ('Minimization process', 2, None, 'minimization-process'),
              ('Minimizing the cost function using gradient descent and '
               'automatic differentiation',
               2,
               None,
               'minimizing-the-cost-function-using-gradient-descent-and-automatic-differentiation'),
              ('Example: Exponential decay',
               2,
               None,
               'example-exponential-decay'),
              ('The function to solve for',
               2,
               None,
               'the-function-to-solve-for'),
              ('The trial solution', 2, None, 'the-trial-solution'),
              ('Setup of Network', 2, None, 'setup-of-network'),
              ('Reformulating the problem',
               2,
               None,
               'reformulating-the-problem'),
              ('More technicalities', 2, None, 'more-technicalities'),
              ('More details', 2, None, 'more-details'),
              ('A possible implementation of a neural network',
               2,
               None,
               'a-possible-implementation-of-a-neural-network'),
              ('Technicalities', 2, None, 'technicalities'),
              ('Final technicalities I', 2, None, 'final-technicalities-i'),
              ('Final technicalities II', 2, None, 'final-technicalities-ii'),
              ('Final technicalities III', 2, None, 'final-technicalities-iii'),
              ('Final technicalities IV', 2, None, 'final-technicalities-iv'),
              ('Back propagation', 2, None, 'back-propagation'),
              ('Gradient descent', 2, None, 'gradient-descent'),
              ('The code for solving the ODE',
               2,
               None,
               'the-code-for-solving-the-ode'),
              ('The network with one input layer, specified number of hidden '
               'layers, and one output layer',
               2,
               None,
               'the-network-with-one-input-layer-specified-number-of-hidden-layers-and-one-output-layer'),
              ('Example: Population growth',
               2,
               None,
               'example-population-growth'),
              ('Setting up the problem', 2, None, 'setting-up-the-problem'),
              ('The trial solution', 2, None, 'the-trial-solution'),
              ('The program using Autograd',
               2,
               None,
               'the-program-using-autograd'),
              ('Using forward Euler to solve the ODE',
               2,
               None,
               'using-forward-euler-to-solve-the-ode'),
              ('Example: Solving the one dimensional Poisson equation',
               2,
               None,
               'example-solving-the-one-dimensional-poisson-equation'),
              ('The specific equation to solve for',
               2,
               None,
               'the-specific-equation-to-solve-for'),
              ('Solving the equation using Autograd',
               2,
               None,
               'solving-the-equation-using-autograd'),
              ('Comparing with a numerical scheme',
               2,
               None,
               'comparing-with-a-numerical-scheme'),
              ('Setting up the code', 2, None, 'setting-up-the-code'),
              ('Partial Differential Equations',
               2,
               None,
               'partial-differential-equations'),
              ('Type of problem', 2, None, 'type-of-problem'),
              ('Network requirements', 2, None, 'network-requirements'),
              ('More details', 2, None, 'more-details'),
              ('Example: The diffusion equation',
               2,
               None,
               'example-the-diffusion-equation'),
              ('Defining the problem', 2, None, 'defining-the-problem'),
              ('Setting up the network using Autograd',
               2,
               None,
               'setting-up-the-network-using-autograd'),
              ('Setting up the network using Autograd; The trial solution',
               2,
               None,
               'setting-up-the-network-using-autograd-the-trial-solution'),
              ('Why the jacobian?', 2, None, 'why-the-jacobian'),
              ('Setting up the network using Autograd; The full program',
               2,
               None,
               'setting-up-the-network-using-autograd-the-full-program'),
              ('Example: Solving the wave equation with Neural Networks',
               2,
               None,
               'example-solving-the-wave-equation-with-neural-networks'),
              ('The problem to solve for', 2, None, 'the-problem-to-solve-for'),
              ('The trial solution', 2, None, 'the-trial-solution'),
              ('The analytical solution', 2, None, 'the-analytical-solution'),
              ('Solving the wave equation - the full program using Autograd',
               2,
               None,
               'solving-the-wave-equation-the-full-program-using-autograd'),
              ('Resources on differential equations and deep learning',
               2,
               None,
               'resources-on-differential-equations-and-deep-learning'),
              ('Convolutional Neural Networks (recognizing images)',
               2,
               None,
               'convolutional-neural-networks-recognizing-images'),
              ('What is the Difference', 2, None, 'what-is-the-difference'),
              ('Neural Networks vs CNNs', 2, None, 'neural-networks-vs-cnns'),
              ('Why CNNS for images, sound files, medical images from CT scans '
               'etc?',
               2,
               None,
               'why-cnns-for-images-sound-files-medical-images-from-ct-scans-etc'),
              ('Regular NNs donâ€™t scale well to full images',
               2,
               None,
               'regular-nns-don-t-scale-well-to-full-images'),
              ('3D volumes of neurons', 2, None, '3d-volumes-of-neurons'),
              ('Layers used to build CNNs',
               2,
               None,
               'layers-used-to-build-cnns'),
              ('Transforming images', 2, None, 'transforming-images'),
              ('CNNs in brief', 2, None, 'cnns-in-brief'),
              ('Key Idea', 2, None, 'key-idea'),
              ('Mathematics of CNNs', 2, None, 'mathematics-of-cnns'),
              ('Convolution Examples: Polynomial multiplication',
               2,
               None,
               'convolution-examples-polynomial-multiplication'),
              ('Efficient Polynomial Multiplication',
               2,
               None,
               'efficient-polynomial-multiplication'),
              ('A more efficient way of coding the above Convolution',
               2,
               None,
               'a-more-efficient-way-of-coding-the-above-convolution'),
              ('Convolution Examples: Principle of Superposition and Periodic '
               'Forces (Fourier Transforms)',
               2,
               None,
               'convolution-examples-principle-of-superposition-and-periodic-forces-fourier-transforms'),
              ('Principle of Superposition',
               2,
               None,
               'principle-of-superposition'),
              ('Simple Code Example', 2, None, 'simple-code-example'),
              ('Wrapping up Fourier transforms',
               2,
               None,
               'wrapping-up-fourier-transforms'),
              ('Finding the Coefficients', 2, None, 'finding-the-coefficients'),
              ('Final words on Fourier Transforms',
               2,
               None,
               'final-words-on-fourier-transforms'),
              ('Two-dimensional Objects', 2, None, 'two-dimensional-objects'),
              ('Cross-Correlation', 2, None, 'cross-correlation'),
              ('More on Dimensionalities', 2, None, 'more-on-dimensionalities'),
              ('Further Dimensionality Remarks',
               2,
               None,
               'further-dimensionality-remarks'),
              ('CNNs in more detail, Lecture from IN5400',
               2,
               None,
               'cnns-in-more-detail-lecture-from-in5400'),
              ('CNNs in more detail, building convolutional neural networks in '
               'Tensorflow and Keras',
               2,
               None,
               'cnns-in-more-detail-building-convolutional-neural-networks-in-tensorflow-and-keras'),
              ('Setting it up', 2, None, 'setting-it-up'),
              ('The MNIST dataset again', 2, None, 'the-mnist-dataset-again'),
              ('Strong correlations', 2, None, 'strong-correlations'),
              ('Layers of a CNN', 2, None, 'layers-of-a-cnn'),
              ('Systematic reduction', 2, None, 'systematic-reduction'),
              ('Prerequisites: Collect and pre-process data',
               2,
               None,
               'prerequisites-collect-and-pre-process-data'),
              ('Importing Keras and Tensorflow',
               2,
               None,
               'importing-keras-and-tensorflow'),
              ('Running with Keras', 2, None, 'running-with-keras'),
              ('Final part', 2, None, 'final-part'),
              ('Final visualization', 2, None, 'final-visualization'),
              ('The CIFAR01 data set', 2, None, 'the-cifar01-data-set'),
              ('Verifying the data set', 2, None, 'verifying-the-data-set'),
              ('Set up  the model', 2, None, 'set-up-the-model'),
              ('Add Dense layers on top', 2, None, 'add-dense-layers-on-top'),
              ('Compile and train the model',
               2,
               None,
               'compile-and-train-the-model'),
              ('Finally, evaluate the model',
               2,
               None,
               'finally-evaluate-the-model')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- Bootstrap navigation bar -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="week5-bs.html">Solving differential equations and start CNNs</a>
  </div>
  <div class="navbar-collapse collapse navbar-responsive-collapse">
    <ul class="nav navbar-nav navbar-right">
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Contents <b class="caret"></b></a>
        <ul class="dropdown-menu">
     <!-- navigation toc: --> <li><a href="._week5-bs001.html#plan-for-week-5" style="font-size: 80%;">Plan for week 5</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs002.html#using-automatic-differentiation" style="font-size: 80%;">Using Automatic differentiation</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs003.html#solving-odes-with-deep-learning" style="font-size: 80%;">Solving ODEs with Deep Learning</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs004.html#ordinary-differential-equations" style="font-size: 80%;">Ordinary Differential Equations</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs047.html#the-trial-solution" style="font-size: 80%;">The trial solution</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs006.html#minimization-process" style="font-size: 80%;">Minimization process</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs007.html#minimizing-the-cost-function-using-gradient-descent-and-automatic-differentiation" style="font-size: 80%;">Minimizing the cost function using gradient descent and automatic differentiation</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs008.html#example-exponential-decay" style="font-size: 80%;">Example: Exponential decay</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs009.html#the-function-to-solve-for" style="font-size: 80%;">The function to solve for</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs047.html#the-trial-solution" style="font-size: 80%;">The trial solution</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs011.html#setup-of-network" style="font-size: 80%;">Setup of Network</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs012.html#reformulating-the-problem" style="font-size: 80%;">Reformulating the problem</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs013.html#more-technicalities" style="font-size: 80%;">More technicalities</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs038.html#more-details" style="font-size: 80%;">More details</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs015.html#a-possible-implementation-of-a-neural-network" style="font-size: 80%;">A possible implementation of a neural network</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs016.html#technicalities" style="font-size: 80%;">Technicalities</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs017.html#final-technicalities-i" style="font-size: 80%;">Final technicalities I</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs018.html#final-technicalities-ii" style="font-size: 80%;">Final technicalities II</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs019.html#final-technicalities-iii" style="font-size: 80%;">Final technicalities III</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs020.html#final-technicalities-iv" style="font-size: 80%;">Final technicalities IV</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs021.html#back-propagation" style="font-size: 80%;">Back propagation</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs022.html#gradient-descent" style="font-size: 80%;">Gradient descent</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs023.html#the-code-for-solving-the-ode" style="font-size: 80%;">The code for solving the ODE</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs024.html#the-network-with-one-input-layer-specified-number-of-hidden-layers-and-one-output-layer" style="font-size: 80%;">The network with one input layer, specified number of hidden layers, and one output layer</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs025.html#example-population-growth" style="font-size: 80%;">Example: Population growth</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs026.html#setting-up-the-problem" style="font-size: 80%;">Setting up the problem</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs047.html#the-trial-solution" style="font-size: 80%;">The trial solution</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs028.html#the-program-using-autograd" style="font-size: 80%;">The program using Autograd</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs029.html#using-forward-euler-to-solve-the-ode" style="font-size: 80%;">Using forward Euler to solve the ODE</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs030.html#example-solving-the-one-dimensional-poisson-equation" style="font-size: 80%;">Example: Solving the one dimensional Poisson equation</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs031.html#the-specific-equation-to-solve-for" style="font-size: 80%;">The specific equation to solve for</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs032.html#solving-the-equation-using-autograd" style="font-size: 80%;">Solving the equation using Autograd</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs033.html#comparing-with-a-numerical-scheme" style="font-size: 80%;">Comparing with a numerical scheme</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs034.html#setting-up-the-code" style="font-size: 80%;">Setting up the code</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs035.html#partial-differential-equations" style="font-size: 80%;">Partial Differential Equations</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs036.html#type-of-problem" style="font-size: 80%;">Type of problem</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs037.html#network-requirements" style="font-size: 80%;">Network requirements</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs038.html#more-details" style="font-size: 80%;">More details</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs039.html#example-the-diffusion-equation" style="font-size: 80%;">Example: The diffusion equation</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs040.html#defining-the-problem" style="font-size: 80%;">Defining the problem</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs041.html#setting-up-the-network-using-autograd" style="font-size: 80%;">Setting up the network using Autograd</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs042.html#setting-up-the-network-using-autograd-the-trial-solution" style="font-size: 80%;">Setting up the network using Autograd; The trial solution</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs043.html#why-the-jacobian" style="font-size: 80%;">Why the jacobian?</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs044.html#setting-up-the-network-using-autograd-the-full-program" style="font-size: 80%;">Setting up the network using Autograd; The full program</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs045.html#example-solving-the-wave-equation-with-neural-networks" style="font-size: 80%;">Example: Solving the wave equation with Neural Networks</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs046.html#the-problem-to-solve-for" style="font-size: 80%;">The problem to solve for</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs047.html#the-trial-solution" style="font-size: 80%;">The trial solution</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs048.html#the-analytical-solution" style="font-size: 80%;">The analytical solution</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs049.html#solving-the-wave-equation-the-full-program-using-autograd" style="font-size: 80%;">Solving the wave equation - the full program using Autograd</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs050.html#resources-on-differential-equations-and-deep-learning" style="font-size: 80%;">Resources on differential equations and deep learning</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs051.html#convolutional-neural-networks-recognizing-images" style="font-size: 80%;">Convolutional Neural Networks (recognizing images)</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs052.html#what-is-the-difference" style="font-size: 80%;">What is the Difference</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs053.html#neural-networks-vs-cnns" style="font-size: 80%;">Neural Networks vs CNNs</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs054.html#why-cnns-for-images-sound-files-medical-images-from-ct-scans-etc" style="font-size: 80%;">Why CNNS for images, sound files, medical images from CT scans etc?</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs055.html#regular-nns-don-t-scale-well-to-full-images" style="font-size: 80%;">Regular NNs donâ€™t scale well to full images</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs056.html#3d-volumes-of-neurons" style="font-size: 80%;">3D volumes of neurons</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs057.html#layers-used-to-build-cnns" style="font-size: 80%;">Layers used to build CNNs</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs058.html#transforming-images" style="font-size: 80%;">Transforming images</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs059.html#cnns-in-brief" style="font-size: 80%;">CNNs in brief</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs060.html#key-idea" style="font-size: 80%;">Key Idea</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs061.html#mathematics-of-cnns" style="font-size: 80%;">Mathematics of CNNs</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs062.html#convolution-examples-polynomial-multiplication" style="font-size: 80%;">Convolution Examples: Polynomial multiplication</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs063.html#efficient-polynomial-multiplication" style="font-size: 80%;">Efficient Polynomial Multiplication</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs064.html#a-more-efficient-way-of-coding-the-above-convolution" style="font-size: 80%;">A more efficient way of coding the above Convolution</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs065.html#convolution-examples-principle-of-superposition-and-periodic-forces-fourier-transforms" style="font-size: 80%;">Convolution Examples: Principle of Superposition and Periodic Forces (Fourier Transforms)</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs066.html#principle-of-superposition" style="font-size: 80%;">Principle of Superposition</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs067.html#simple-code-example" style="font-size: 80%;">Simple Code Example</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs068.html#wrapping-up-fourier-transforms" style="font-size: 80%;">Wrapping up Fourier transforms</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs069.html#finding-the-coefficients" style="font-size: 80%;">Finding the Coefficients</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs070.html#final-words-on-fourier-transforms" style="font-size: 80%;">Final words on Fourier Transforms</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs071.html#two-dimensional-objects" style="font-size: 80%;">Two-dimensional Objects</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs072.html#cross-correlation" style="font-size: 80%;">Cross-Correlation</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs073.html#more-on-dimensionalities" style="font-size: 80%;">More on Dimensionalities</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs074.html#further-dimensionality-remarks" style="font-size: 80%;">Further Dimensionality Remarks</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs075.html#cnns-in-more-detail-lecture-from-in5400" style="font-size: 80%;">CNNs in more detail, Lecture from IN5400</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs076.html#cnns-in-more-detail-building-convolutional-neural-networks-in-tensorflow-and-keras" style="font-size: 80%;">CNNs in more detail, building convolutional neural networks in Tensorflow and Keras</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs077.html#setting-it-up" style="font-size: 80%;">Setting it up</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs078.html#the-mnist-dataset-again" style="font-size: 80%;">The MNIST dataset again</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs079.html#strong-correlations" style="font-size: 80%;">Strong correlations</a></li>
     <!-- navigation toc: --> <li><a href="#layers-of-a-cnn" style="font-size: 80%;">Layers of a CNN</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs081.html#systematic-reduction" style="font-size: 80%;">Systematic reduction</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs082.html#prerequisites-collect-and-pre-process-data" style="font-size: 80%;">Prerequisites: Collect and pre-process data</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs083.html#importing-keras-and-tensorflow" style="font-size: 80%;">Importing Keras and Tensorflow</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs084.html#running-with-keras" style="font-size: 80%;">Running with Keras</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs085.html#final-part" style="font-size: 80%;">Final part</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs086.html#final-visualization" style="font-size: 80%;">Final visualization</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs087.html#the-cifar01-data-set" style="font-size: 80%;">The CIFAR01 data set</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs088.html#verifying-the-data-set" style="font-size: 80%;">Verifying the data set</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs089.html#set-up-the-model" style="font-size: 80%;">Set up  the model</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs090.html#add-dense-layers-on-top" style="font-size: 80%;">Add Dense layers on top</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs091.html#compile-and-train-the-model" style="font-size: 80%;">Compile and train the model</a></li>
     <!-- navigation toc: --> <li><a href="._week5-bs092.html#finally-evaluate-the-model" style="font-size: 80%;">Finally, evaluate the model</a></li>

        </ul>
      </li>
    </ul>
  </div>
</div>
</div> <!-- end of navigation bar -->
<div class="container">
<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p> <!-- add vertical space -->
<a name="part0080"></a>
<!-- !split  -->
<h2 id="layers-of-a-cnn" class="anchor">Layers of a CNN </h2>
<p>The layers of a convolutional neural network arrange neurons in 3D: width, height and depth.  
The input image is typically a square matrix of depth 3. 
</p>

<p>A <b>convolution</b> is performed on the image which outputs
a 3D volume of neurons. The weights to the input are arranged in a number of 2D matrices, known as <b>filters</b>.
</p>

<p>Each filter slides along the input image, taking the dot product
between each small part of the image and the filter, in all depth
dimensions. This is then passed through a non-linear function,
typically the <b>Rectified Linear (ReLu)</b> function, which serves as the
activation of the neurons in the first convolutional layer. This is
further passed through a <b>pooling layer</b>, which reduces the size of the
convolutional layer, e.g. by taking the maximum or average across some
small regions, and this serves as input to the next convolutional
layer.
</p>

<p>
<!-- navigation buttons at the bottom of the page -->
<ul class="pagination">
<li><a href="._week5-bs079.html">&laquo;</a></li>
  <li><a href="._week5-bs000.html">1</a></li>
  <li><a href="">...</a></li>
  <li><a href="._week5-bs072.html">73</a></li>
  <li><a href="._week5-bs073.html">74</a></li>
  <li><a href="._week5-bs074.html">75</a></li>
  <li><a href="._week5-bs075.html">76</a></li>
  <li><a href="._week5-bs076.html">77</a></li>
  <li><a href="._week5-bs077.html">78</a></li>
  <li><a href="._week5-bs078.html">79</a></li>
  <li><a href="._week5-bs079.html">80</a></li>
  <li class="active"><a href="._week5-bs080.html">81</a></li>
  <li><a href="._week5-bs081.html">82</a></li>
  <li><a href="._week5-bs082.html">83</a></li>
  <li><a href="._week5-bs083.html">84</a></li>
  <li><a href="._week5-bs084.html">85</a></li>
  <li><a href="._week5-bs085.html">86</a></li>
  <li><a href="._week5-bs086.html">87</a></li>
  <li><a href="._week5-bs087.html">88</a></li>
  <li><a href="._week5-bs088.html">89</a></li>
  <li><a href="._week5-bs089.html">90</a></li>
  <li><a href="">...</a></li>
  <li><a href="._week5-bs092.html">93</a></li>
  <li><a href="._week5-bs081.html">&raquo;</a></li>
</ul>
<!-- ------------------- end of main content --------------- -->
</div>  <!-- end container -->
<!-- include javascript, jQuery *first* -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>
<!-- Bootstrap footer
<footer>
<a href="https://..."><img width="250" align=right src="https://..."></a>
</footer>
-->
<center style="font-size:80%">
<!-- copyright only on the titlepage -->
</center>
</body>
</html>

